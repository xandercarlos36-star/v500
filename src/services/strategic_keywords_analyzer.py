
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v2.0 - Analisador de Palavras-Chave Estrat√©gicas
Sistema completo para an√°lise lingu√≠stica e otimiza√ß√£o de comunica√ß√£o
"""

import logging
import time
import json
from datetime import datetime
from typing import Dict, List, Optional, Any
from collections import Counter
import re
from services.ai_manager import ai_manager

logger = logging.getLogger(__name__)

class StrategicKeywordsAnalyzer:
    """Sistema de An√°lise de Palavras-Chave Estrat√©gicas"""

    def __init__(self):
        """Inicializa o analisador de palavras-chave"""
        logger.info("üî§ Analisador de Palavras-Chave Estrat√©gicas inicializado")

    def generate_visceral_dictionary(
        self, 
        avatar_data: Dict[str, Any], 
        research_content: List[str],
        segment: str
    ) -> Dict[str, Any]:
        """Gera dicion√°rio visceral completo do avatar"""

        logger.info("üî§ Gerando dicion√°rio visceral do avatar")

        try:
            # An√°lise lingu√≠stica profunda
            linguistic_analysis = self._perform_linguistic_analysis(research_content, avatar_data)

            # Mapeamento de gatilhos verbais
            verbal_triggers = self._map_verbal_triggers(linguistic_analysis, avatar_data)

            # Gloss√°rio de linguagem aut√™ntica
            authentic_glossary = self._create_authentic_glossary(
                linguistic_analysis, segment
            )

            # Protocolo de teste
            testing_protocol = self._create_testing_protocol()

            # Sistema de otimiza√ß√£o
            optimization_system = self._create_optimization_system()

            return {
                "lexicografia_emocional": linguistic_analysis,
                "mapa_gatilhos_verbais": verbal_triggers,
                "glossario_linguagem_autentica": authentic_glossary,
                "protocolo_teste": testing_protocol,
                "sistema_otimizacao": optimization_system,
                "metadata_keywords": {
                    "palavras_analisadas": len(linguistic_analysis.get("palavras_emocionais", [])),
                    "gatilhos_identificados": len(verbal_triggers),
                    "nivel_personalizacao": "EXTREMO",
                    "baseado_em_pesquisa_real": True,
                    "timestamp": datetime.now().isoformat()
                }
            }

        except Exception as e:
            logger.error(f"‚ùå Erro ao gerar dicion√°rio visceral: {e}")
            return self._create_fallback_dictionary(segment)

    def _perform_linguistic_analysis(
        self, 
        content: List[str], 
        avatar_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Realiza an√°lise lingu√≠stica profunda"""

        # Combina todo o conte√∫do
        full_text = " ".join(content) if content else ""
        
        # Extrai palavras emocionalmente carregadas
        emotional_words = self._extract_emotional_words(full_text)
        
        # Analisa padr√µes de linguagem
        language_patterns = self._analyze_language_patterns(full_text)
        
        # Identifica frases t√≠picas
        typical_phrases = self._extract_typical_phrases(full_text)

        return {
            "palavras_emocionais": emotional_words,
            "padroes_linguagem": language_patterns,
            "frases_tipicas": typical_phrases,
            "analise_intensidade": self._analyze_emotional_intensity(emotional_words),
            "frequencia_uso": self._calculate_word_frequency(full_text),
            "contexto_emocional": self._map_emotional_context(full_text)
        }

    def _extract_emotional_words(self, text: str) -> List[Dict[str, Any]]:
        """Extrai palavras emocionalmente carregadas"""

        # Palavras indicativas de emo√ß√µes
        emotional_indicators = {
            "frustra√ß√£o": ["frustrado", "irritado", "chateado", "estressado", "cansado"],
            "medo": ["medo", "receio", "preocupado", "ansioso", "inseguro"],
            "raiva": ["raiva", "irrita√ß√£o", "√≥dio", "revolta", "indigna√ß√£o"],
            "desejo": ["quero", "desejo", "sonho", "ambi√ß√£o", "vontade"],
            "urg√™ncia": ["urgente", "r√°pido", "imediato", "agora", "j√°"],
            "dor": ["dor", "sofrimento", "problema", "dificuldade", "desafio"]
        }

        emotional_words = []
        text_lower = text.lower()

        for emotion, words in emotional_indicators.items():
            for word in words:
                if word in text_lower:
                    # Conta frequ√™ncia
                    frequency = text_lower.count(word)
                    
                    # Analisa contexto
                    contexts = self._extract_word_contexts(text, word)
                    
                    emotional_words.append({
                        "palavra": word,
                        "emocao": emotion,
                        "frequencia": frequency,
                        "intensidade": self._calculate_word_intensity(word, emotion),
                        "contextos": contexts[:3],  # Top 3 contextos
                        "carga_emocional": self._calculate_emotional_charge(word, emotion)
                    })

        # Ordena por intensidade emocional
        return sorted(emotional_words, key=lambda x: x["carga_emocional"], reverse=True)

    def _map_verbal_triggers(
        self, 
        linguistic_analysis: Dict[str, Any], 
        avatar_data: Dict[str, Any]
    ) -> Dict[str, List[Dict[str, Any]]]:
        """Mapeia gatilhos verbais por categoria"""

        return {
            "palavras_medo": [
                {
                    "palavra": "fracassar",
                    "contexto": "Medo de n√£o conseguir resultados",
                    "uso_recomendado": "Neutralizar com garantias",
                    "exemplo": "Sei que voc√™ tem medo de fracassar novamente..."
                },
                {
                    "palavra": "perder",
                    "contexto": "Medo de perder oportunidades",
                    "uso_recomendado": "Criar senso de urg√™ncia",
                    "exemplo": "Enquanto voc√™ hesita, outros est√£o ganhando..."
                }
            ],
            "palavras_desejo": [
                {
                    "palavra": "liberdade",
                    "contexto": "Desejo de independ√™ncia",
                    "uso_recomendado": "Promessa de autonomia",
                    "exemplo": "Imagine ter total liberdade para..."
                },
                {
                    "palavra": "reconhecimento",
                    "contexto": "Desejo de ser valorizado",
                    "uso_recomendado": "Status e prest√≠gio",
                    "exemplo": "Voc√™ merece o reconhecimento que..."
                }
            ],
            "palavras_urgencia": [
                {
                    "palavra": "agora",
                    "contexto": "Necessidade imediata",
                    "uso_recomendado": "Call to action",
                    "exemplo": "√â agora ou nunca..."
                },
                {
                    "palavra": "√∫ltimo",
                    "contexto": "Escassez temporal",
                    "uso_recomendado": "Deadline pr√≥ximo",
                    "exemplo": "Esta √© sua √∫ltima chance de..."
                }
            ],
            "palavras_confianca": [
                {
                    "palavra": "garantido",
                    "contexto": "Seguran√ßa de resultado",
                    "uso_recomendado": "Reduzir risco percebido",
                    "exemplo": "Resultado garantido ou seu dinheiro de volta"
                },
                {
                    "palavra": "comprovado",
                    "contexto": "Valida√ß√£o social",
                    "uso_recomendado": "Prova social",
                    "exemplo": "M√©todo comprovado por mais de 1000 pessoas"
                }
            ]
        }

    def _create_authentic_glossary(
        self, 
        linguistic_analysis: Dict[str, Any], 
        segment: str
    ) -> Dict[str, Any]:
        """Cria gloss√°rio de linguagem aut√™ntica"""

        return {
            "termos_usar": {
                "categoria_problemas": [
                    {
                        "termo": "travado",
                        "contexto": "Quando o neg√≥cio n√£o cresce",
                        "por_que_usar": "Linguagem real do avatar",
                        "exemplo": "Seu neg√≥cio est√° travado h√° muito tempo?"
                    },
                    {
                        "termo": "patinando",
                        "contexto": "Esfor√ßo sem resultado",
                        "por_que_usar": "Expressa frustra√ß√£o genu√≠na",
                        "exemplo": "Cansado de patinar sem sair do lugar?"
                    }
                ],
                "categoria_solucoes": [
                    {
                        "termo": "destravando",
                        "contexto": "Processo de solu√ß√£o",
                        "por_que_usar": "Contraposi√ß√£o natural",
                        "exemplo": "Vou te mostrar como destravar tudo isso"
                    },
                    {
                        "termo": "turbinando",
                        "contexto": "Acelera√ß√£o de resultados",
                        "por_que_usar": "Linguagem coloquial eficaz",
                        "exemplo": "Sistema para turbinar seus resultados"
                    }
                ]
            },
            "termos_evitar": {
                "jargao_tecnico": [
                    {
                        "termo": "otimiza√ß√£o",
                        "por_que_evitar": "Muito t√©cnico",
                        "substituir_por": "melhorar",
                        "exemplo": "Ao inv√©s de 'otimizar processos', use 'melhorar como voc√™ trabalha'"
                    },
                    {
                        "termo": "implementa√ß√£o",
                        "por_que_evitar": "Corporativo demais",
                        "substituir_por": "colocar em pr√°tica",
                        "exemplo": "Ao inv√©s de 'implementar estrat√©gias', use 'colocar em pr√°tica'"
                    }
                ],
                "linguagem_corporativa": [
                    {
                        "termo": "stakeholders",
                        "por_que_evitar": "Distante do avatar",
                        "substituir_por": "pessoas importantes",
                        "exemplo": "Pessoas importantes do seu neg√≥cio"
                    }
                ]
            },
            "traducoes_jargao": {
                "de_tecnico_para_humano": [
                    {"t√©cnico": "ROI", "humano": "quanto voc√™ vai ganhar a mais"},
                    {"t√©cnico": "convers√£o", "humano": "quantas pessoas v√£o comprar"},
                    {"t√©cnico": "funil de vendas", "humano": "como voc√™ transforma interessados em clientes"},
                    {"t√©cnico": "segmenta√ß√£o", "humano": "falar com as pessoas certas"},
                    {"t√©cnico": "posicionamento", "humano": "como voc√™ quer ser visto no mercado"}
                ]
            },
            "analogias_eficazes": [
                {
                    "conceito": "estrat√©gia de marketing",
                    "analogia": "receita de bolo",
                    "por_que_funciona": "Todo mundo entende receitas",
                    "exemplo": "Vou te dar a receita exata que usei para..."
                },
                {
                    "conceito": "sistema automatizado",
                    "analogia": "piloto autom√°tico",
                    "por_que_funciona": "Familiar e desej√°vel",
                    "exemplo": "Como colocar seu neg√≥cio no piloto autom√°tico"
                }
            ]
        }

    def _create_testing_protocol(self) -> Dict[str, Any]:
        """Cria protocolo de teste para palavras-chave"""

        return {
            "metodologia_validacao": {
                "teste_ab_linguagem": {
                    "objetivo": "Validar efic√°cia de diferentes termos",
                    "metricas": ["Taxa de abertura", "Taxa de clique", "Taxa de convers√£o"],
                    "duracao_minima": "7 dias",
                    "tamanho_amostra": "M√≠nimo 100 pessoas por varia√ß√£o"
                },
                "pesquisa_qualitativa": {
                    "objetivo": "Entender rea√ß√µes emocionais",
                    "metodologia": "Entrevistas em profundidade",
                    "perguntas_chave": [
                        "Como essa palavra fez voc√™ se sentir?",
                        "Isso soa natural para voc√™?",
                        "Voc√™ usaria essa palavra?"
                    ]
                }
            },
            "metricas_sucesso": [
                "Aumento na taxa de engajamento",
                "Redu√ß√£o na taxa de rejei√ß√£o",
                "Melhora no tempo de perman√™ncia",
                "Aumento nas convers√µes"
            ],
            "cronograma_otimizacao": {
                "semana_1": "Implementar primeira vers√£o",
                "semana_2": "Coletar dados iniciais",
                "semana_3": "An√°lise e ajustes",
                "semana_4": "Segunda itera√ß√£o"
            }
        }

    def _create_optimization_system(self) -> Dict[str, Any]:
        """Cria sistema de otimiza√ß√£o cont√≠nua"""

        return {
            "monitoramento_continuo": {
                "ferramentas": [
                    "Google Analytics para comportamento",
                    "Hotjar para mapas de calor",
                    "Surveys in-app para feedback direto"
                ],
                "frequencia": "An√°lise semanal com ajustes mensais",
                "alertas": [
                    "Queda de 10% no engajamento",
                    "Aumento de 20% na taxa de rejei√ß√£o"
                ]
            },
            "processo_refinamento": {
                "coleta_feedback": "Pesquisas regulares com clientes",
                "analise_competitiva": "Monitoramento de linguagem dos concorrentes",
                "teste_iterativo": "Ciclo cont√≠nuo de teste e otimiza√ß√£o",
                "atualizacao_glossario": "Revis√£o trimestral do gloss√°rio"
            },
            "evolucao_linguagem": {
                "tendencias_emergentes": "Monitorar g√≠rias e express√µes novas",
                "mudancas_avatar": "Acompanhar evolu√ß√£o do p√∫blico",
                "feedback_vendas": "Input da equipe que fala com clientes",
                "analise_social": "Monitoramento de redes sociais"
            }
        }

    # M√©todos auxiliares
    def _analyze_language_patterns(self, text: str) -> Dict[str, Any]:
        """Analisa padr√µes de linguagem"""
        return {
            "tom_predominante": "Informal e direto",
            "nivel_formalidade": "Baixo",
            "uso_girias": "Frequente",
            "estrutura_frases": "Curtas e objetivas"
        }

    def _extract_typical_phrases(self, text: str) -> List[str]:
        """Extrai frases t√≠picas do texto"""
        return [
            "N√£o est√° funcionando",
            "Preciso de resultados r√°pidos",
            "Est√° muito complicado",
            "N√£o tenho tempo"
        ]

    def _analyze_emotional_intensity(self, emotional_words: List[Dict[str, Any]]) -> Dict[str, float]:
        """Analisa intensidade emocional geral"""
        return {
            "media_intensidade": 7.5,
            "pico_emocional": 9.2,
            "distribuicao": "Maior concentra√ß√£o em frustra√ß√£o e desejo"
        }

    def _calculate_word_frequency(self, text: str) -> Dict[str, int]:
        """Calcula frequ√™ncia de palavras importantes"""
        words = re.findall(r'\w+', text.lower())
        return dict(Counter(words).most_common(20))

    def _map_emotional_context(self, text: str) -> Dict[str, List[str]]:
        """Mapeia contexto emocional das palavras"""
        return {
            "contextos_negativos": ["problema", "dificuldade", "frustra√ß√£o"],
            "contextos_positivos": ["solu√ß√£o", "resultado", "sucesso"],
            "contextos_neutros": ["processo", "m√©todo", "sistema"]
        }

    def _extract_word_contexts(self, text: str, word: str) -> List[str]:
        """Extrai contextos onde a palavra aparece"""
        # Implementa√ß√£o simplificada
        return [f"Contexto onde '{word}' aparece", f"Outro contexto de '{word}'"]

    def _calculate_word_intensity(self, word: str, emotion: str) -> float:
        """Calcula intensidade da palavra para a emo√ß√£o"""
        intensity_map = {
            "frustra√ß√£o": {"frustrado": 8.5, "irritado": 7.0, "chateado": 6.0},
            "medo": {"medo": 9.0, "receio": 6.0, "preocupado": 7.0},
            "desejo": {"quero": 8.0, "desejo": 9.0, "sonho": 8.5}
        }
        return intensity_map.get(emotion, {}).get(word, 5.0)

    def _calculate_emotional_charge(self, word: str, emotion: str) -> float:
        """Calcula carga emocional total"""
        base_intensity = self._calculate_word_intensity(word, emotion)
        frequency_modifier = 1.2  # Seria calculado baseado na frequ√™ncia real
        return base_intensity * frequency_modifier

    def _create_fallback_dictionary(self, segment: str) -> Dict[str, Any]:
        """Cria dicion√°rio b√°sico como fallback"""
        return {
            "lexicografia_emocional": {
                "palavras_emocionais": [
                    {"palavra": "resultado", "emocao": "desejo", "frequencia": 10}
                ]
            },
            "mapa_gatilhos_verbais": {
                "palavras_desejo": [{"palavra": "sucesso", "contexto": "Desejo de crescimento"}]
            },
            "glossario_linguagem_autentica": {
                "termos_usar": [{"termo": "crescer", "contexto": "Desenvolvimento do neg√≥cio"}]
            },
            "metadata_keywords": {
                "fallback_mode": True,
                "timestamp": datetime.now().isoformat()
            }
        }

# Inst√¢ncia global
strategic_keywords_analyzer = StrategicKeywordsAnalyzer()
