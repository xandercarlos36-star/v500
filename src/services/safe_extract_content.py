#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v2.0 - Safe Content Extraction
Extra√ß√£o segura de conte√∫do com valida√ß√£o rigorosa
"""

import logging
import time
from typing import Optional, Dict, Any, Tuple, List  # Added List import
from services.robust_content_extractor import robust_content_extractor
from services.content_quality_validator import content_quality_validator
from services.url_resolver import url_resolver

logger = logging.getLogger(__name__)

class SafeContentExtractor:
    """Extrator seguro de conte√∫do com valida√ß√£o rigorosa"""
    
    def __init__(self):
        """Inicializa o extrator seguro"""
        self.min_content_length = 500
        self.min_quality_score = 60.0
        self.max_extraction_time = 30  # segundos
        
        logger.info("Safe Content Extractor inicializado")
    
    def safe_extract_content(self, url: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Extrai conte√∫do de forma segura com valida√ß√£o completa
        
        Returns:
            Dict com 'success', 'content', 'metadata', 'validation', 'error'
        """
        
        result = {
            'success': False,
            'content': None,
            'metadata': {},
            'validation': {},
            'error': None,
            'url': url,
            'timestamp': time.time()
        }
        
        try:
            start_time = time.time()
            
            # 1. Valida URL
            if not self._validate_url(url):
                result['error'] = f"URL inv√°lida: {url}"
                logger.error(f"‚ùå {result['error']}")
                return result
            
            # 2. Resolve redirecionamentos
            resolved_url = url_resolver.resolve_redirect_url(url)
            if resolved_url != url:
                logger.info(f"üîÑ URL resolvida: {url} -> {resolved_url}")
                result['metadata']['resolved_url'] = resolved_url
                url = resolved_url
            
            # 3. Valida URL resolvida
            if not self._validate_url(resolved_url):
                result['error'] = f"URL resolvida inv√°lida: {resolved_url}"
                logger.error(f"‚ùå {result['error']}")
                return result
            
            # 4. Extrai conte√∫do com timeout
            extraction_start = time.time()
            content = self._extract_with_timeout(url)
            extraction_time = time.time() - extraction_start
            
            result['metadata']['extraction_time'] = extraction_time
            
            if not content:
                result['error'] = "Nenhum conte√∫do extra√≠do"
                logger.error(f"‚ùå {result['error']} para {url}")
                return result
            
            # 5. Valida tamanho m√≠nimo
            if len(content) < self.min_content_length:
                result['error'] = f"Conte√∫do muito pequeno: {len(content)} < {self.min_content_length}"
                logger.error(f"‚ùå {result['error']} para {url}")
                return result
            
            # 6. Valida qualidade do conte√∫do
            validation = content_quality_validator.validate_content(content, url, context)
            result['validation'] = validation
            
            if not validation['valid']:
                result['error'] = f"Conte√∫do de baixa qualidade: {validation['reason']}"
                logger.error(f"‚ùå {result['error']} para {url}")
                return result
            
            if validation['score'] < self.min_quality_score:
                result['error'] = f"Score de qualidade muito baixo: {validation['score']:.1f}% < {self.min_quality_score}%"
                logger.error(f"‚ùå {result['error']} para {url}")
                return result
            
            # 7. Sucesso - conte√∫do v√°lido
            result['success'] = True
            result['content'] = content
            result['metadata'].update({
                'content_length': len(content),
                'word_count': len(content.split()),
                'quality_score': validation['score'],
                'total_time': time.time() - start_time
            })
            
            logger.info(f"‚úÖ Extra√ß√£o segura bem-sucedida: {len(content)} chars, qualidade {validation['score']:.1f}%")
            return result
            
        except Exception as e:
            result['error'] = f"Erro na extra√ß√£o: {str(e)}"
            result['metadata']['total_time'] = time.time() - start_time if 'start_time' in locals() else 0
            logger.error(f"‚ùå {result['error']} para {url}")
            return result
    
    def _validate_url(self, url: str) -> bool:
        """Valida se a URL √© v√°lida"""
        if not url:
            return False
        
        if not url.startswith(('http://', 'https://')):
            return False
        
        # Verifica se n√£o √© URL suspeita
        suspicious_patterns = [
            'javascript:', 'data:', 'mailto:', 'tel:', 'ftp:',
            'localhost', '127.0.0.1', '0.0.0.0'
        ]
        
        url_lower = url.lower()
        if any(pattern in url_lower for pattern in suspicious_patterns):
            return False
        
        return True
    
    def _extract_with_timeout(self, url: str) -> Optional[str]:
        """Extrai conte√∫do com timeout"""
        import signal
        
        def timeout_handler(signum, frame):
            raise TimeoutError("Extra√ß√£o excedeu tempo limite")
        
        # Configura timeout (apenas em sistemas Unix)
        try:
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(self.max_extraction_time)
            
            content = robust_content_extractor.extract_content(url)
            
            signal.alarm(0)  # Cancela timeout
            return content
            
        except AttributeError:
            # Sistema Windows - sem timeout por signal
            return robust_content_extractor.extract_content(url)
        except TimeoutError:
            logger.error(f"‚è∞ Timeout na extra√ß√£o de {url}")
            return None
        except Exception as e:
            signal.alarm(0)  # Cancela timeout em caso de erro
            raise e
    
    def batch_safe_extract(
        self, 
        urls: List[str], 
        context: Dict[str, Any] = None,
        max_workers: int = 3
    ) -> Dict[str, Dict[str, Any]]:
        """Extrai conte√∫do de m√∫ltiplas URLs de forma segura"""
        
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        results = {}
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_url = {
                executor.submit(self.safe_extract_content, url, context): url 
                for url in urls
            }
            
            for future in as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    result = future.result()
                    results[url] = result
                except Exception as e:
                    results[url] = {
                        'success': False,
                        'error': f"Erro na extra√ß√£o paralela: {str(e)}",
                        'url': url,
                        'timestamp': time.time()
                    }
        
        # Estat√≠sticas do lote
        successful = sum(1 for result in results.values() if result['success'])
        total = len(results)
        
        logger.info(f"üìä Extra√ß√£o em lote: {successful}/{total} sucessos ({successful/total*100:.1f}%)")
        
        return results
    
    def get_extraction_stats(self) -> Dict[str, Any]:
        """Retorna estat√≠sticas de extra√ß√£o"""
        return robust_content_extractor.get_extractor_stats()

# Inst√¢ncia global
safe_content_extractor = SafeContentExtractor()

# Fun√ß√£o de conveni√™ncia
def safe_extract_content(url: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
    """Fun√ß√£o de conveni√™ncia para extra√ß√£o segura"""
    return safe_content_extractor.safe_extract_content(url, context)
