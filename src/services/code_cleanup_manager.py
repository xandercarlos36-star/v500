#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v2.0 - Code Cleanup Manager
Sistema para identificar e remover c√≥digo desnecess√°rio
"""

import os
import logging
import re
import ast
from typing import Dict, List, Any, Set, Tuple
from pathlib import Path
from datetime import datetime
from services.auto_save_manager import salvar_etapa

logger = logging.getLogger(__name__)

class CodeCleanupManager:
    """Gerenciador de limpeza de c√≥digo"""

    def __init__(self):
        """Inicializa o gerenciador de limpeza"""
        self.project_root = Path("src")
        self.disposable_patterns = [
            r'# TODO.*',
            r'# FIXME.*',
            r'# XXX.*',
            r'print\s*\([^)]*debug[^)]*\)',
            r'console\.log\s*\([^)]*\)',
            r'import\s+pdb.*',
            r'pdb\.set_trace\(\)',
            r'debugger;',
            r'\/\*.*test.*\*\/',
            r'#.*test.*placeholder.*',
            r'#.*mock.*data.*',
            r'#.*temporary.*',
            r'#.*hardcoded.*',
            r'if\s+False\s*:',
            r'if\s+0\s*:',
            r'pass\s*#.*'
        ]

        self.unused_imports = set()
        self.dead_code_blocks = []
        self.disposable_files = []

        logger.info("üßπ Code Cleanup Manager inicializado")

    def analyze_codebase(self, session_id: str) -> Dict[str, Any]:
        """Analisa a base de c√≥digo para identificar itens descart√°veis"""

        try:
            logger.info("üîç Analisando base de c√≥digo para limpeza...")

            analysis_results = {
                'session_id': session_id,
                'timestamp': datetime.now().isoformat(),
                'disposable_files': [],
                'unused_imports': [],
                'dead_code_blocks': [],
                'hardcoded_values': [],
                'debug_statements': [],
                'mock_placeholders': [],
                'temporary_code': [],
                'duplicate_code': [],
                'cleanup_summary': {}
            }

            # Analisa todos os arquivos Python
            python_files = list(self.project_root.rglob("*.py"))

            for file_path in python_files:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()

                    # Analisa arquivo espec√≠fico
                    file_analysis = self._analyze_file(file_path, content)

                    # Adiciona resultados ao an√°lise geral
                    if file_analysis['is_disposable']:
                        analysis_results['disposable_files'].append({
                            'path': str(file_path),
                            'reason': file_analysis['disposable_reason'],
                            'size_bytes': len(content),
                            'last_modified': datetime.fromtimestamp(file_path.stat().st_mtime).isoformat()
                        })

                    analysis_results['unused_imports'].extend(file_analysis['unused_imports'])
                    analysis_results['dead_code_blocks'].extend(file_analysis['dead_code'])
                    analysis_results['hardcoded_values'].extend(file_analysis['hardcoded_values'])
                    analysis_results['debug_statements'].extend(file_analysis['debug_statements'])
                    analysis_results['mock_placeholders'].extend(file_analysis['mock_placeholders'])
                    analysis_results['temporary_code'].extend(file_analysis['temporary_code'])

                except Exception as e:
                    logger.warning(f"Erro ao analisar {file_path}: {e}")
                    continue

            # Identifica c√≥digo duplicado
            analysis_results['duplicate_code'] = self._find_duplicate_code(python_files)

            # Gera resumo da limpeza
            analysis_results['cleanup_summary'] = self._generate_cleanup_summary(analysis_results)

            # Salva an√°lise
            salvar_etapa(
                "code_cleanup_analysis",
                analysis_results,
                session_id=session_id,
                categoria="code_cleanup"
            )

            logger.info(f"‚úÖ An√°lise de limpeza conclu√≠da: {len(analysis_results['disposable_files'])} arquivos descart√°veis encontrados")
            return analysis_results

        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise de limpeza: {e}")
            return {
                'session_id': session_id,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }

    def _analyze_file(self, file_path: Path, content: str) -> Dict[str, Any]:
        """Analisa um arquivo espec√≠fico"""

        analysis = {
            'file_path': str(file_path),
            'is_disposable': False,
            'disposable_reason': '',
            'unused_imports': [],
            'dead_code': [],
            'hardcoded_values': [],
            'debug_statements': [],
            'mock_placeholders': [],
            'temporary_code': []
        }

        try:
            # Verifica se √© arquivo de teste ou backup
            file_name = file_path.name.lower()
            if any(pattern in file_name for pattern in ['test_', '_test', 'backup', 'copy', 'temp', 'tmp', 'old']):
                analysis['is_disposable'] = True
                analysis['disposable_reason'] = f"Arquivo de teste/backup/tempor√°rio: {file_name}"

            # Verifica se √© arquivo vazio ou s√≥ coment√°rios
            content_lines = [line.strip() for line in content.split('\n') if line.strip()]
            code_lines = [line for line in content_lines if not line.startswith('#') and not line.startswith('"""') and not line.startswith("'''")]

            if len(code_lines) < 5:
                analysis['is_disposable'] = True
                analysis['disposable_reason'] = f"Arquivo muito pequeno ou vazio: {len(code_lines)} linhas de c√≥digo"

            # Procura por padr√µes espec√≠ficos
            lines = content.split('\n')
            for i, line in enumerate(lines):
                line_stripped = line.strip()

                # Debug statements
                if any(pattern in line_stripped.lower() for pattern in ['print(', 'console.log', 'pdb.set_trace', 'debugger']):
                    if 'debug' in line_stripped.lower() or 'test' in line_stripped.lower():
                        analysis['debug_statements'].append({
                            'line_number': i + 1,
                            'content': line_stripped,
                            'file': str(file_path)
                        })

                # Mock/placeholder code
                if any(pattern in line_stripped.lower() for pattern in ['mock', 'placeholder', 'todo', 'fixme', 'hardcoded']):
                    analysis['mock_placeholders'].append({
                        'line_number': i + 1,
                        'content': line_stripped,
                        'file': str(file_path)
                    })

                # Temporary code
                if any(pattern in line_stripped.lower() for pattern in ['temporary', 'temp', 'delete me', 'remove this']):
                    analysis['temporary_code'].append({
                        'line_number': i + 1,
                        'content': line_stripped,
                        'file': str(file_path)
                    })

                # Hardcoded values (strings/n√∫meros suspeitos)
                hardcoded_patterns = [
                    r'api_key\s*=\s*["\'][^"\']{20,}["\']',
                    r'password\s*=\s*["\'][^"\']+["\']',
                    r'secret\s*=\s*["\'][^"\']+["\']',
                    r'token\s*=\s*["\'][^"\']{20,}["\']'
                ]

                for pattern in hardcoded_patterns:
                    if re.search(pattern, line_stripped, re.IGNORECASE):
                        analysis['hardcoded_values'].append({
                            'line_number': i + 1,
                            'content': line_stripped[:50] + "...",
                            'file': str(file_path),
                            'type': 'sensitive_data'
                        })

            # Analisa imports n√£o utilizados (an√°lise b√°sica)
            try:
                tree = ast.parse(content)
                imports = []
                used_names = set()

                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            imports.append(alias.name)
                    elif isinstance(node, ast.ImportFrom):
                        for alias in node.names:
                            imports.append(alias.name)
                    elif isinstance(node, ast.Name):
                        used_names.add(node.id)

                # Identifica imports n√£o utilizados
                for imp in imports:
                    if imp not in used_names and imp not in ['sys', 'os', 'logging']:
                        analysis['unused_imports'].append({
                            'import': imp,
                            'file': str(file_path)
                        })

            except Exception as e:
                logger.debug(f"Erro na an√°lise AST de {file_path}: {e}")

        except Exception as e:
            logger.warning(f"Erro na an√°lise detalhada de {file_path}: {e}")

        return analysis

    def _find_duplicate_code(self, python_files: List[Path]) -> List[Dict[str, Any]]:
        """Encontra c√≥digo duplicado"""

        duplicates = []

        try:
            code_blocks = {}

            for file_path in python_files:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()

                    # Divide em blocos de fun√ß√£o/classe
                    tree = ast.parse(content)

                    for node in ast.walk(tree):
                        if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                            # Extrai o c√≥digo do n√≥
                            start_line = node.lineno - 1
                            end_line = getattr(node, 'end_lineno', start_line + 10) if hasattr(node, 'end_lineno') else start_line + 10

                            lines = content.split('\n')[start_line:end_line]
                            block_content = '\n'.join(lines)

                            # Normaliza o conte√∫do (remove espa√ßos extras)
                            normalized = re.sub(r'\s+', ' ', block_content).strip()

                            if len(normalized) > 100:  # S√≥ analisa blocos significativos
                                if normalized in code_blocks:
                                    duplicates.append({
                                        'content_preview': normalized[:100] + "...",
                                        'files': [code_blocks[normalized], str(file_path)],
                                        'block_type': type(node).__name__,
                                        'estimated_lines': len(lines)
                                    })
                                else:
                                    code_blocks[normalized] = str(file_path)

                except Exception as e:
                    logger.debug(f"Erro ao analisar duplicatas em {file_path}: {e}")
                    continue

        except Exception as e:
            logger.warning(f"Erro na busca por c√≥digo duplicado: {e}")

        return duplicates[:20]  # Limita a 20 duplicatas

    def _generate_cleanup_summary(self, analysis_results: Dict[str, Any]) -> Dict[str, Any]:
        """Gera resumo da limpeza"""

        summary = {
            'total_disposable_files': len(analysis_results.get('disposable_files', [])),
            'total_unused_imports': len(analysis_results.get('unused_imports', [])),
            'total_debug_statements': len(analysis_results.get('debug_statements', [])),
            'total_mock_placeholders': len(analysis_results.get('mock_placeholders', [])),
            'total_hardcoded_values': len(analysis_results.get('hardcoded_values', [])),
            'total_duplicate_blocks': len(analysis_results.get('duplicate_code', [])),
            'estimated_cleanup_impact': {},
            'recommended_actions': []
        }

        # Calcula impacto estimado
        disposable_size = sum(file.get('size_bytes', 0) for file in analysis_results.get('disposable_files', []))
        summary['estimated_cleanup_impact'] = {
            'files_to_remove': summary['total_disposable_files'],
            'bytes_to_save': disposable_size,
            'kb_to_save': round(disposable_size / 1024, 2),
            'estimated_performance_gain': min(100, summary['total_unused_imports'] * 2),
            'code_maintainability_improvement': min(100, (summary['total_mock_placeholders'] + summary['total_debug_statements']) * 3)
        }

        # Gera recomenda√ß√µes
        if summary['total_disposable_files'] > 0:
            summary['recommended_actions'].append(f"Remover {summary['total_disposable_files']} arquivos descart√°veis")

        if summary['total_unused_imports'] > 5:
            summary['recommended_actions'].append(f"Limpar {summary['total_unused_imports']} imports n√£o utilizados")

        if summary['total_debug_statements'] > 0:
            summary['recommended_actions'].append(f"Remover {summary['total_debug_statements']} declara√ß√µes de debug")

        if summary['total_hardcoded_values'] > 0:
            summary['recommended_actions'].append(f"Mover {summary['total_hardcoded_values']} valores hardcoded para configura√ß√£o")

        if summary['total_duplicate_blocks'] > 0:
            summary['recommended_actions'].append(f"Refatorar {summary['total_duplicate_blocks']} blocos de c√≥digo duplicado")

        return summary

    def execute_safe_cleanup(self, analysis_results: Dict[str, Any], session_id: str, dry_run: bool = True) -> Dict[str, Any]:
        """Executa limpeza segura do c√≥digo"""

        try:
            logger.info(f"üßπ Executando limpeza {'(simula√ß√£o)' if dry_run else '(real)'}...")

            cleanup_results = {
                'session_id': session_id,
                'timestamp': datetime.now().isoformat(),
                'dry_run': dry_run,
                'actions_taken': [],
                'files_processed': 0,
                'cleanup_summary': {}
            }

            # Lista arquivos para remo√ß√£o
            disposable_files = analysis_results.get('disposable_files', [])

            if disposable_files:
                logger.info(f"üìã ARQUIVOS MARCADOS PARA REMO√á√ÉO ({len(disposable_files)} itens):")
                for file_info in disposable_files:
                    logger.info(f"   - {file_info['path']} ({file_info['reason']})")

                    if not dry_run:
                        try:
                            file_path = Path(file_info['path'])
                            if file_path.exists():
                                # Move para pasta de backup antes de remover
                                backup_dir = Path("backup_removed_files")
                                backup_dir.mkdir(exist_ok=True)

                                backup_path = backup_dir / file_path.name
                                file_path.rename(backup_path)

                                cleanup_results['actions_taken'].append(f"Movido para backup: {file_info['path']}")
                                cleanup_results['files_processed'] += 1
                        except Exception as e:
                            logger.error(f"Erro ao processar {file_info['path']}: {e}")

            # Remove debug statements (apenas em dry_run por seguran√ßa)
            debug_statements = analysis_results.get('debug_statements', [])
            if debug_statements and dry_run:
                logger.info(f"üêõ DEBUG STATEMENTS ENCONTRADOS ({len(debug_statements)} itens):")
                for debug_info in debug_statements[:10]:  # Mostra apenas os primeiros 10
                    logger.info(f"   - {debug_info['file']}:{debug_info['line_number']} - {debug_info['content'][:50]}...")

            cleanup_results['cleanup_summary'] = {
                'disposable_files_processed': len(disposable_files),
                'debug_statements_found': len(debug_statements),
                'total_actions_planned': len(disposable_files) + len(debug_statements),
                'actions_executed': cleanup_results['files_processed']
            }

            # Salva resultados da limpeza
            salvar_etapa(
                "code_cleanup_execution",
                cleanup_results,
                session_id=session_id,
                categoria="code_cleanup"
            )

            logger.info(f"‚úÖ Limpeza {'simulada' if dry_run else 'executada'} - {cleanup_results['files_processed']} arquivos processados")
            return cleanup_results

        except Exception as e:
            logger.error(f"‚ùå Erro na limpeza: {e}")
            return {
                'session_id': session_id,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }

    def _list_removable_files(self) -> List[Path]:
        """Lista todos os arquivos que s√£o considerados remov√≠veis"""
        removable_files = []
        try:
            # Adiciona padr√µes de nomenclatura de arquivos para considerar como remov√≠veis
            disposable_file_patterns = ['test_', '_test', 'backup', 'copy', 'temp', 'tmp', 'old', '.pyc', '.log', '__pycache__']
            
            for pattern in disposable_file_patterns:
                # Procura por arquivos que correspondem aos padr√µes em todo o diret√≥rio do projeto
                removable_files.extend(self.project_root.rglob(f'*{pattern}*'))
                
                # Remove duplicatas
                removable_files = list(set(removable_files))

        except Exception as e:
            logger.warning(f"Erro ao listar arquivos remov√≠veis: {e}")
        return removable_files

    def cleanup_temporary_files(self) -> Dict[str, Any]:
        """Remove arquivos tempor√°rios e desnecess√°rios - LISTA ANTES DE REMOVER"""

        try:
            logger.info("üßπ Iniciando limpeza de arquivos tempor√°rios...")

            # LISTA TODOS OS ARQUIVOS ANTES DE REMOVER
            files_to_remove = self._list_removable_files()

            logger.info(f"üìã Arquivos identificados para remo√ß√£o:")
            for file_path in files_to_remove:
                logger.info(f"  üóëÔ∏è {file_path}")

            # Confirma antes de remover
            if len(files_to_remove) > 0:
                logger.info(f"‚ö†Ô∏è {len(files_to_remove)} arquivos ser√£o removidos...")

            cleanup_stats = {
                'files_to_remove': files_to_remove,
                'files_removed': 0,
                'space_freed': 0,
                'categories_cleaned': []
            }
            
            # Realiza a remo√ß√£o dos arquivos
            for file_path in files_to_remove:
                try:
                    if file_path.is_file():
                        file_size = file_path.stat().st_size
                        file_path.unlink()
                        cleanup_stats['files_removed'] += 1
                        cleanup_stats['space_freed'] += file_size
                        logger.info(f"  ‚úÖ Removido: {file_path} ({file_size} bytes)")
                    elif file_path.is_dir():
                        # Pode adicionar l√≥gica para remover diret√≥rios vazios se necess√°rio
                        pass
                except Exception as e:
                    logger.warning(f"Erro ao remover {file_path}: {e}")

            # Calcula o espa√ßo liberado em KB e MB
            cleanup_stats['space_freed_kb'] = round(cleanup_stats['space_freed'] / 1024, 2)
            cleanup_stats['space_freed_mb'] = round(cleanup_stats['space_freed'] / (1024 * 1024), 2)

            logger.info(f"‚úÖ Limpeza de arquivos tempor√°rios conclu√≠da. {cleanup_stats['files_removed']} arquivos removidos, {cleanup_stats['space_freed_kb']:.2f} KB liberados.")

            return cleanup_stats

        except Exception as e:
            logger.error(f"‚ùå Erro na limpeza de arquivos tempor√°rios: {e}")
            return {
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }


# Inst√¢ncia global
code_cleanup_manager = CodeCleanupManager()